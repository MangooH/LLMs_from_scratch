{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RAG Basic\n",
    " - Indexing\n",
    " - Retrieval\n",
    " - Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Indexing`\n",
    "> 문서를 쉽게 검색할 수 있도록\n",
    "- 우리가 실제로 로드하고 Retriever 를 통해 검색하고자 하는 외부 문서를 다루는 것\n",
    "- Retriever 의 목표는 입력된 Query 에 따라 관련 docs 를 찾아내는 것입니다. \n",
    "- 이때, 단순한 텍스트보다 숫자 벡터를 비교하는 것이 훨씬 쉽기에 수년간 텍스트 문서를 숫자 표현으로 압축하는 다양한 방법이 개발되었습니다.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./img/indexing.png\" alt=\"Indexing\" style=\"width: 60%; display: inline-block; margin: 0 2%;\">\n",
    "    <img src=\"./img/embedding.png\" alt=\"Embedding\" style=\"width: 30%; display: inline-block; margin: 0 2%;\">\n",
    "</div>\n",
    "\n",
    "**Word to Vector**\n",
    "1. 문서의 단어 빈도를 분석하여 희소 벡터를 만드는 통계적 방법\n",
    "2. 최근에는 머신러닝을 이용한 임베딩 방법\n",
    "    - 문서를 고정된 길이의 벡터로 압축하여 매우 강력한 검색 방법을 제공\n",
    "    - 임베딩 모델은 제한된 컨텍스트 윈도우를 가지고 있어 문서를 여러 조각으로 나누고 각 조각을 벡터로 압축\n",
    "    - 질문도 동일한 방식으로 임베딩하여 벡터를 생성하고, 이 벡터들을 비교하여 질문과 관련된 문서를 찾아냅니다.\n",
    "\n",
    "**Addtional IDEA**\n",
    "- 오른쪽 그림과 같이 문서를 임베딩할 때 문서가 3차원 공간의 한 점으로 투영된다고 상상할 수 있습니다.\n",
    "- 이 위치는 문서의 의미나 내용에 따라 결정됩니다.\n",
    "- 따라서 공간 내 가까운 위치에 있는 문서들은 유사한 의미를 포함하게 됩니다.\n",
    "- 이 아이디어는 현대 벡터 스토어에서 사용되는 많은 검색 및 검색 방법의 기초가 됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Retrieval`\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./img/\bretrieval.png\" alt=\"Indexing\" style=\"width: 40%; display: inline-block; margin: 0 2%;\">\n",
    "    <img src=\"./img/\bvarious.png\" alt=\"Various\" style=\"width: 50%; display: inline-block; margin: 0 2%;\">\n",
    "</div>\n",
    "\n",
    "- 문서를 임베딩하여 3D 공간에 투영하고, 질문도 동일하게 임베딩하여 해당 공간에 투영합니다. \n",
    "- 그런 다음 질문 주위의 로컬 네이버후드 검색을 통해 근처에 있는 문서를 찾아냅니다 (유사한 의미를 가진 문서를 검색합니다)\n",
    "- 우리는 원하는 k 개 만큼의 문서를 선택할 수 있습니다.\n",
    "- 여러 임베딩 모델, 인덱스, 문서 로더 및 스플리터를 조합하여 다양한 인덱싱 및 검색 방법을 테스트할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Generation`\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./img/generation.png\" alt=\"Indexing\" style=\"width: 80%;\">\n",
    "</div>\n",
    "\n",
    "- 관련된 문서 조각들을 검색 후, 프롬프트를 완성합니다.\n",
    "- 이를 컨텍스트 윈도우에 넣고 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Embedding` & `Similarity between query and docs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain python-dotenv bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "question = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a cat.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embd = OpenAIEmbeddings()\n",
    "query_result = embd.embed_query(question)\n",
    "document_result = embd.embed_query(document)\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8807044730847654\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
